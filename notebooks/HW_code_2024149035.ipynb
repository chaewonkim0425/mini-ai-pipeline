{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0f62098-c627-474e-9a03-e594b8fec2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install datasets transformers scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daaeab49-3eee-4dfc-9527-18f7b48745a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc581e6f-654f-4ddc-9dc9-f04fd54209c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,\n",
       " 500,\n",
       " {'text': 'Bangladesh paralysed by strikes Opposition activists have brought many towns and cities in Bangladesh to a halt, the day after 18 people died in explosions at a political rally.',\n",
       "  'label': 0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"ag_news\")\n",
    "\n",
    "train_small = dataset[\"train\"].shuffle(seed=42).select(range(2000))\n",
    "test_small  = dataset[\"test\"].shuffle(seed=42).select(range(500))\n",
    "\n",
    "label2name = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\n",
    "\n",
    "len(train_small), len(test_small), train_small[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c9d5479-b4d5-4a53-a93f-6940235ce266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.53\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "\n",
    "label_counts = Counter(int(x[\"label\"]) for x in train_small)\n",
    "default_label = label_counts.most_common(1)[0][0]\n",
    "\n",
    "world_keywords = [\n",
    "    \"government\", \"president\", \"country\", \"nation\", \"war\", \"minister\",\n",
    "    \"election\", \"vote\", \"conflict\", \"leader\", \"peace\", \"leader\"\n",
    "]\n",
    "sports_keywords = [\n",
    "    \"match\", \"win\", \"team\", \"game\", \"player\", \"cup\", \"league\",\n",
    "    \"goal\", \"coach\", \"season\", \"tournament\", \"final\", \"olympic\", \"score\"\n",
    "]\n",
    "business_keywords = [\n",
    "    \"market\", \"stock\", \"company\", \"business\", \"profit\", \"trade\", \"share\",\n",
    "    \"investment\", \"bank\", \"loan\", \"revenue\", \"tax\", \"oil\", \"dollar\", \"gas\"\n",
    "]\n",
    "scitech_keywords = [\n",
    "    \"technology\", \"software\", \"internet\", \"research\", \"science\",\n",
    "    \"computer\", \"device\", \"phone\", \"chip\", \"AI\", \"robot\", \"network\", \"data\",\n",
    "    \"nasa\", \"space\", \"satellite\"\n",
    "]\n",
    "\n",
    "def baseline_predict(text: str) -> int:\n",
    "    t = text.lower()\n",
    "    scores = [0, 0, 0, 0]  # [World, Sports, Business, Sci/Tech]\n",
    "\n",
    "    for w in world_keywords:\n",
    "        if w in t:\n",
    "            scores[0] += 1\n",
    "    for w in sports_keywords:\n",
    "        if w in t:\n",
    "            scores[1] += 1\n",
    "    for w in business_keywords:\n",
    "        if w in t:\n",
    "            scores[2] += 1\n",
    "    for w in scitech_keywords:\n",
    "        if w in t:\n",
    "            scores[3] += 1\n",
    "\n",
    "    if max(scores) == 0:\n",
    "        return default_label\n",
    "\n",
    "    return scores.index(max(scores))\n",
    "\n",
    "texts  = [x[\"text\"] for x in test_small]\n",
    "labels = [int(x[\"label\"]) for x in test_small]\n",
    "\n",
    "baseline_preds = [baseline_predict(t) for t in texts]\n",
    "baseline_acc = accuracy_score(labels, baseline_preds)\n",
    "\n",
    "print(\"Baseline accuracy:\", baseline_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f053a1ce-133b-4b40-9003-822e4266d63b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"textattack/distilbert-base-uncased-ag-news\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22755af5-5ea3-4b7f-8e36-7645a7139636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy : 0.53\n",
      "Pipeline accuracy : 0.928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def pipeline_predict(text_list):\n",
    "    enc = tokenizer(\n",
    "        text_list,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    enc = {k: v.to(device) for k, v in enc.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**enc)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    return preds.cpu().tolist()\n",
    "\n",
    "texts  = [x[\"text\"] for x in test_small]\n",
    "labels = [int(x[\"label\"]) for x in test_small]\n",
    "\n",
    "batch_size = 32\n",
    "pipeline_preds = []\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch_text = texts[i:i+batch_size]\n",
    "    batch_pred = pipeline_predict(batch_text)\n",
    "    pipeline_preds.extend(batch_pred)\n",
    "\n",
    "pipeline_acc = accuracy_score(labels, pipeline_preds)\n",
    "\n",
    "print(\"Baseline accuracy :\", baseline_acc)\n",
    "print(\"Pipeline accuracy :\", pipeline_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83e8f91d-4113-4601-af6d-ba1a686151d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy on the test set:  0.5300\n",
      "Pipeline accuracy on the test set:  0.9280\n",
      "\n",
      "Examples where the baseline and the pipeline make different predictions:\n",
      "\n",
      "================================================================================\n",
      "Text:           Indian board plans own telecast of Australia series The Indian cricket board said on Wednesday it was making arrangements on its own to broadcast next month #39;s test series against Australia, which is under threat because of a raging TV rights dispute.\n",
      "True label:     Sports\n",
      "Baseline pred:  Sci/Tech\n",
      "Pipeline pred:  Sports\n",
      "================================================================================\n",
      "Text:           REVIEW: 'Half-Life 2' a Tech Masterpiece (AP) AP - It's been six years since Valve Corp. perfected the first-person shooter with \"Half-Life.\" Video games have come a long way since, with better graphics and more options than ever. Still, relatively few games have mustered this one's memorable characters and original science fiction story.\n",
      "True label:     Sci/Tech\n",
      "Baseline pred:  Sports\n",
      "Pipeline pred:  Sci/Tech\n",
      "================================================================================\n",
      "Text:           China's inflation rate slows sharply but problems remain (AFP) AFP - China's inflation rate eased sharply in October as government efforts to cool the economy began to really bite, with food prices, one of the main culprits, showing some signs of slowing, official data showed.\n",
      "True label:     World\n",
      "Baseline pred:  World\n",
      "Pipeline pred:  Business\n",
      "================================================================================\n",
      "Text:           ADV: Try Currency Trading Risk-Free 30 Days 24-hour commission-free trading, 100-to-1 leverage of your capital, and Dealbook Fx 2 - our free advanced trading software. Sign up for our free 30-day trial and receive one-on-one training.\n",
      "True label:     Business\n",
      "Baseline pred:  World\n",
      "Pipeline pred:  Business\n",
      "================================================================================\n",
      "Text:           OPEC Can Raise Output Capacity by 1 Mln Barrels/Day (Update1) The Organization of Petroleum Exporting Countries, which supplies a third of the world #39;s crude oil, can raise production capacity by 1 million barrels a day by year-end, OPEC President Purnomo Yusgiantoro said.\n",
      "True label:     Business\n",
      "Baseline pred:  World\n",
      "Pipeline pred:  Business\n"
     ]
    }
   ],
   "source": [
    "label2name = {\n",
    "    0: \"World\",\n",
    "    1: \"Sports\",\n",
    "    2: \"Business\",\n",
    "    3: \"Sci/Tech\",\n",
    "}\n",
    "\n",
    "print(f\"Baseline accuracy on the test set:  {baseline_acc:.4f}\")\n",
    "print(f\"Pipeline accuracy on the test set:  {pipeline_acc:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Examples where the baseline and the pipeline make different predictions:\\n\")\n",
    "\n",
    "count = 0\n",
    "for text, y_true, y_base, y_pipe in zip(texts, labels, baseline_preds, pipeline_preds):\n",
    "    if y_base != y_pipe and count < 5:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Text:          \", text)\n",
    "        print(\"True label:    \", label2name[y_true])\n",
    "        print(\"Baseline pred: \", label2name[y_base])\n",
    "        print(\"Pipeline pred: \", label2name[y_pipe])\n",
    "        count += 1\n",
    "\n",
    "if count == 0:\n",
    "    print(\"The baseline and the pipeline made almost identical predictions.\")\n",
    "    print(\"Below are three random examples from the test set.\\n\")\n",
    "    for i in range(3):\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Text:          \", texts[i])\n",
    "        print(\"True label:    \", label2name[labels[i]])\n",
    "        print(\"Baseline pred: \", label2name[baseline_preds[i]])\n",
    "        print(\"Pipeline pred: \", label2name[pipeline_preds[i]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
